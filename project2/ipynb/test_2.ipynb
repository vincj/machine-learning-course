{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"data/tmp.csv\",\"r\") as f:\n",
    "    reader = csv.reader(f,delimiter = \",\")\n",
    "    data = list(reader)\n",
    "    row_count = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176953"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2,  0,  4,  0,  0,  4],\n",
       "        [ 2,  0,  3,  0,  6,  0],\n",
       "        [10,  4,  7,  0,  0,  6],\n",
       "        [ 2,  0,  8,  2,  0,  0],\n",
       "        [ 2,  0,  4,  0,  0,  4],\n",
       "        [ 2,  0,  3,  0,  6,  0],\n",
       "        [10,  4,  7,  0,  0,  6],\n",
       "        [ 2,  0,  8,  2,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = sp.lil_matrix([[2,0,4,0,0,4],[2,0,3,0,6,0],[10,4,7,0,0,6],[2,0,8,2,0,0],[2,0,4,0,0,4],[2,0,3,0,6,0],[10,4,7,0,0,6],[2,0,8,2,0,0]])\n",
    "ar.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 6], dtype=int32), array([0, 0], dtype=int32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_,col_ = ar[:,1].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(ar, metric='cosine')\n",
    "#item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.00772212,  0.63726187,  0.0513167 ],\n",
       "       [ 0.00772212,  0.        ,  0.55007873,  0.01941932],\n",
       "       [ 0.63726187,  0.55007873,  0.        ,  0.42646067],\n",
       "       [ 0.0513167 ,  0.01941932,  0.42646067,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "nz_row, nz_col = ar.nonzero()\n",
    "nz_train = list(zip(nz_row, nz_col))\n",
    "#print(nz_train)\n",
    "for i in range(ar.shape[1]):\n",
    "    sub_mat = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2, 0, 4, 0, 0],\n",
       "        [3, 0, 5, 0, 2],\n",
       "        [1, 0, 0, 0, 6],\n",
       "        [7, 4, 8, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_small = sp.lil_matrix([[2,0,4,0,0],[3,0,5,0,2],[1,0,0,0,6],[7,4,8,0,0]])\n",
    "a_small.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.05688087,  0.92647854,  0.09437588],\n",
       "       [ 0.05688087,  0.        ,  0.59996444,  0.12874922],\n",
       "       [ 0.92647854,  0.59996444,  0.        ,  0.89867833],\n",
       "       [ 0.09437588,  0.12874922,  0.89867833,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pairwise_distances(a_small, metric='cosine')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  4,  0,  0,  1],\n",
       "       [10,  0,  4,  5,  0,  1],\n",
       "       [ 1,  0,  0,  0,  6,  1],\n",
       "       [ 7,  4,  8,  0,  0,  1],\n",
       "       [ 2,  0,  4,  0,  0,  1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_array = np.array([[2,0,4,0,0,1],[10,0,4,5,0,1],[1,0,0,0,6,1],[7,4,8,0,0,1],[2,0,4,0,0,1]])\n",
    "a_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.32243977,  0.89380115,  0.10046817,  0.        ],\n",
       "       [ 0.32243977,  0.        ,  0.85025349,  0.24190894,  0.32243977],\n",
       "       [ 0.89380115,  0.85025349,  0.        ,  0.88617792,  0.89380115],\n",
       "       [ 0.10046817,  0.24190894,  0.88617792,  0.        ,  0.10046817],\n",
       "       [ 0.        ,  0.32243977,  0.89380115,  0.10046817,  0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pairwise_distances(a_array, metric='cosine')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "dataset = spark.createDataFrame(\n",
    "    [(Vectors.dense([0.0]), 0.0),\n",
    "     (Vectors.dense([0.4]), 1.0),\n",
    "     (Vectors.dense([0.5]), 0.0),\n",
    "     (Vectors.dense([0.6]), 1.0),\n",
    "     (Vectors.dense([1.0]), 1.0)] * 10,\n",
    "    [\"features\", \"label\"])\n",
    "lr = LogisticRegression()\n",
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator)\n",
    "cvModel = cv.fit(dataset)\n",
    "evaluator.evaluate(cvModel.transform(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ALSExample\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "dataset = spark.createDataFrame(\n",
    "    [(Vectors.dense([0.0]), 0.0),\n",
    "     (Vectors.dense([0.4]), 1.0),\n",
    "     (Vectors.dense([0.5]), 0.0),\n",
    "     (Vectors.dense([0.6]), 1.0),\n",
    "     (Vectors.dense([1.0]), 1.0)] * 10,\n",
    "    [\"features\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator)\n",
    "cvModel = cv.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='LogisticRegression_429eacf663efbef26ffe', name='maxIter', doc='max number of iterations (>= 0).'): 0},\n",
       " {Param(parent='LogisticRegression_429eacf663efbef26ffe', name='maxIter', doc='max number of iterations (>= 0).'): 1}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2,  0,  4,  0,  0,  4],\n",
       "        [ 2,  0,  3,  0,  6,  0],\n",
       "        [10,  4,  7,  0,  0,  6],\n",
       "        [ 2,  0,  8,  2,  0,  0],\n",
       "        [ 2,  0,  4,  0,  0,  4],\n",
       "        [ 2,  0,  3,  0,  6,  0],\n",
       "        [10,  4,  7,  0,  0,  6],\n",
       "        [ 2,  0,  8,  2,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = sp.lil_matrix([[2,0,4,0,0,4],[2,0,3,0,6,0],[10,4,7,0,0,6],[2,0,8,2,0,0],[2,0,4,0,0,4],[2,0,3,0,6,0],[10,4,7,0,0,6],[2,0,8,2,0,0]])\n",
    "ar.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matrix type must be 'f', 'd', 'F', or 'D'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e3d88a788fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#get SVD components from train matrix. Choose k.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#s_diag_matrix=np.diag(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vincent/anaconda3/lib/python3.5/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36msvds\u001b[0;34m(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     \u001b[0;31m# This is not a stable way to approach the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     eigvals, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,\n\u001b[0;32m-> 1754\u001b[0;31m                                   ncv=ncv, which=which, v0=v0)\n\u001b[0m\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;31m# In 'LM' mode try to be clever about small eigenvalues.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vincent/anaconda3/lib/python3.5/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     params = _SymmetricArpackParams(n, k, A.dtype.char, matvec, mode,\n\u001b[1;32m   1600\u001b[0m                                     \u001b[0mM_matvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv_matvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m                                     ncv, v0, maxiter, which, tol)\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_ARPACK_LOCK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vincent/anaconda3/lib/python3.5/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n, k, tp, matvec, mode, M_matvec, Minv_matvec, sigma, ncv, v0, maxiter, which, tol)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         _ArpackParams.__init__(self, n, k, tp, mode, sigma,\n\u001b[0;32m--> 512\u001b[0;31m                                ncv, v0, maxiter, which, tol)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncv\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vincent/anaconda3/lib/python3.5/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n, k, tp, mode, sigma, ncv, v0, maxiter, which, tol)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fdFD'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matrix type must be 'f', 'd', 'F', or 'D'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mv0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matrix type must be 'f', 'd', 'F', or 'D'"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(ar, k = 4)\n",
    "#s_diag_matrix=np.diag(s)\n",
    "#X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "#print 'User-based CF MSE: ' + str(rmse(X_pred, test_data_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    >>> from pyspark.ml.classification import LogisticRegression\n",
    "    >>> lr = LogisticRegression()\n",
    "    \n",
    "    >>> output = ParamGridBuilder() \\\n",
    "    ...     .baseOn({lr.labelCol: 'l'}) \\\n",
    "    ...     .baseOn([lr.predictionCol, 'p']) \\\n",
    "    ...     .addGrid(lr.regParam, [1.0, 2.0]) \\\n",
    "    ...     .addGrid(lr.maxIter, [1, 5]) \\\n",
    "    ...     .build()\n",
    "    \n",
    "    >>> expected = [\n",
    "    ...     {lr.regParam: 1.0, lr.maxIter: 1, lr.labelCol: 'l', lr.predictionCol: 'p'},\n",
    "    ...     {lr.regParam: 2.0, lr.maxIter: 1, lr.labelCol: 'l', lr.predictionCol: 'p'},\n",
    "    ...     {lr.regParam: 1.0, lr.maxIter: 5, lr.labelCol: 'l', lr.predictionCol: 'p'},\n",
    "    ...     {lr.regParam: 2.0, lr.maxIter: 5, lr.labelCol: 'l', lr.predictionCol: 'p'}]\n",
    "    \n",
    "    >>> len(output) == len(expected)\n",
    "    True\n",
    "    >>> all([m in expected for m in output])\n",
    "    True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "output = ParamGridBuilder() \\\n",
    "    .baseOn({lr.labelCol: 'l'}) \\\n",
    "    .baseOn([lr.predictionCol, 'p']) \\\n",
    "    .addGrid(lr.regParam, [1.0, 2.0]) \\\n",
    "    .addGrid(lr.maxIter, [1, 5]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='labelCol', doc='label column name.'): 'l',\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='regParam', doc='regularization parameter (>= 0).'): 1.0,\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='maxIter', doc='max number of iterations (>= 0).'): 1,\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='predictionCol', doc='prediction column name.'): 'p'},\n",
       " {Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='labelCol', doc='label column name.'): 'l',\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='regParam', doc='regularization parameter (>= 0).'): 1.0,\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='predictionCol', doc='prediction column name.'): 'p'},\n",
       " {Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='labelCol', doc='label column name.'): 'l',\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='regParam', doc='regularization parameter (>= 0).'): 2.0,\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='maxIter', doc='max number of iterations (>= 0).'): 1,\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='predictionCol', doc='prediction column name.'): 'p'},\n",
       " {Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='labelCol', doc='label column name.'): 'l',\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='regParam', doc='regularization parameter (>= 0).'): 2.0,\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       "  Param(parent='LogisticRegression_487881b0cfb8e88c13c2', name='predictionCol', doc='prediction column name.'): 'p'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
